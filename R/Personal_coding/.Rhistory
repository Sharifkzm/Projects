knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(tinytex.verbose = TRUE)
load("russian_trolls_sample")
library(tm)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(rvest)
library(tidyverse)
library(jsonlite)
library(ggcorrplot)
load("russian_trolls_sample")
library(tm)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(rvest)
library(tidyverse)
library(jsonlite)
library(ggcorrplot)
setwd("C:/Users/mmsha/OneDrive/Desktop/The Ghosts in the Machine/R/Text as Data/Problem Set 2")
load("russian_trolls_sample")
load("russian_trolls_sample.Rdata")
library(tm)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(rvest)
library(tidyverse)
library(jsonlite)
library(ggcorrplot)
load("russian_trolls_sample.Rdata")
library(sentimentr)
library(tm)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(rvest)
library(tidyverse)
library(jsonlite)
library(ggcorrplot)
library(sentimentr)
load("russian_trolls_sample.Rdata")
hillary_dictionary <- dictionary(list(hillary_terms = c("hillary",
"email", "e-mail",
"emails", "e-mails",
"benghazi","libya",
"consulate", "weiner",
"pizza","body count")))
russian_trolls_sample %>%
tokens_lookup(dictionary = my_dictionary) %>%
dfm()
russian_trolls_tokens = tokens(russian_trolls_tokens, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
russian_trolls_tokens = tokens(russian_trolls_sample, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
russian_trolls_corupus = corpus(russian_trolls_sample)
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
# russian_trolls_dfm =  dfm(russian_trolls_tokens)
russian_trolls_tokens %>%
tokens_lookup(dictionary = my_dictionary) %>%
dfm()
russian_trolls_corupus = corpus(russian_trolls_sample)
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
# russian_trolls_dfm =  dfm(russian_trolls_tokens)
russian_trolls_tokens %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
View(russian_trolls_sample)
RightTroll = tokens_subset(russian_trolls_tokens,
subset=screen_name == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
RightTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
RightTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
LeftTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
View(russian_trolls_tokens)
hillary_dictionary <- dictionary(list(hillary_terms = c("hillary",
"email", "e-mail",
"emails", "e-mails",
"benghazi","libya",
"consulate", "weiner",
"pizza","body count",
"haiti", "iran")))
russian_trolls_corupus = corpus(russian_trolls_sample)
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
# russian_trolls_dfm =  dfm(russian_trolls_tokens)
russian_trolls_tokens %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
RightTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
LeftTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
RightTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
LeftTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
View(russian_trolls_tokens)
help(sentiment+by)
help(sentiment_by)
RightTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
LeftTroll = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
# Convert DFM to a data frame for easier handling
RightTroll_keywords <- convert(RightTroll_dfm, to = "data.frame")
LeftTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
RightTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
LeftTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
# Convert DFM to a data frame for easier handling
RightTroll_keywords <- convert(RightTroll_dfm, to = "data.frame")
# Optionally, sum the counts across documents if you want the total per keyword
RightTroll_sum <- rowSums(RightTroll_keywords[-1]) # Excludes the document-feature counts column
# Create a data frame with the results
RightTroll_table <- data.frame(Keyword = names(RightTroll_sum), Count = RightTroll_sum)
View(RightTroll_keywords)
View(LeftTroll_dfm)
RightTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum(
LeftTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
RightTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
LeftTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "LeftTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
View(LeftTroll)
LeftTroll@docvars[["segid_"]]
View(RightTroll)
RightTroll_dfm = tokens_subset(russian_trolls_tokens,
subset=account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm() %>% sum()
RightTroll_dfm_dict = RightTroll_dfm %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
View(RightTroll)
View(russian_trolls_tokens)
russian_trolls_corupus = corpus(russian_trolls_sample)
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
russian_trolls_tokens %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
View(russian_trolls_tokens)
russian_trolls_corupus = corpus(russian_trolls_sample)
russian_trolls_tokens = tokens(russian_trolls_corupus, remove_numbers = TRUE,
remove_punct = TRUE, remove_url = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_select(pattern = stopwords('en'), selection = 'remove') %>%
tokens_wordstem(language = "en")
russian_trolls_tokens_overlap = russian_trolls_tokens %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
View(russian_trolls_tokens_overlap)
# Subset tokens for RightTroll
RightTroll_tokens <- tokens_subset(russian_trolls_tokens,
subset = account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary)
# Create a binary DFM
RightTroll_dfm <- dfm(RightTroll_tokens) %>%
dfm_trim(min_count = 1) %>% # Ensure tokens appear at least once
dfm_weight(scheme = "boolean") # Convert counts to binary
View(RightTroll_dfm)
RightTroll_dfm <- tokens_subset(russian_trolls_tokens,
subset = account_category == "RightTroll") %>%
tokens_lookup(dictionary = hillary_dictionary) %>%
dfm()
# Summarize counts per keyword
keyword_counts <- textstat_frequency(RightTroll_dfm)
# Create the dataframe
df <- data.frame(Keyword = keyword_counts$feature,
Count = keyword_counts$frequency,
Account_Category = "RightTroll")
View(df)
View(RightTroll_dfm)
